---
title: "Code components"
author: "Matt"
format:
  revealjs:
    slide-number: true
    show-slide-number: all
    scrollable: false
    preview-link: auto
    fig-width: 7
    fig-height: 4
    toc: true
    toc-depth: 1
    number-sections: false
    chalkboard: true
    page-layout: full
    # height: 1080
    # width: 1920
---

# Many stimuli (visual search)

---

* In visual search tasks (for example) you need to put say 100 individual letters on the screen in different positions.
* This would require you to make 100 Text stims and supply each one's x and y and letter content
* However since you can generate Text stims in code, this becomes a much easier task -- just create them in a loop


---

:::{.callout-important title="response needed"}
refer to the official psychopy demo (timestamp 4:42)

[Getting started with Code Components in PsychoPy (by making a visual search task!](https://youtu.be/0dJgLf7BxbE)
:::


# Fields

Fields can be constants or variables.

## Constants for fields

To present an image you can supply the image's filename directly in the `Image` field ('constant' method).

::: {.callout-tip title="method 1 using a constant"}
![](demos/variables/Screenshot 2024-07-18 135559.png){width="100%"}
:::

## Variables for fields

To present the same image you can supply the image's filename in a spreadsheet and use the column header as a variable ('variable' method)

::: {.callout-tip title="method 2 using a reference to the spreadsheet"}
![](demos/variables/Screenshot 2024-07-18 135839.png){width="100%"}
![](demos/variables/Screenshot 2024-07-18 133914.png){width="25%"}
:::

## Why use variables in fields?

* The 'variable' method allows you to present a sequence of images by passing a list of their names through the `Image` component in a loop.

* Variable names are usually column headers in the spreadsheet that controls the loop, as in the previous example.

* Variable names can also be things that you declare explicitly in code 

## Declaring variables for fields in code

Handle the cats in code

```{python}
# Make a list called `cats` containing the filenames.
cats = ['cat1.jpg', 'cat2.jpg', 'cat3.jpg']

# Set the index `i` to 0 (python starts counting from zero not one)
i = 0

# Make a variable called `this_cat` and point it at the i'th cat
this_cat = cats[i]

# increment the index so that the next trial gets the next cat in the list
i = i + 1
```

Now we can use `this_cat` to reference the current trial's image of a cat.


## Which tab to put the code in

Use "Begin Experiment" tab to set up the list and set the index to zero

![](demos/variables/Screenshot 2024-07-18 150858.png)

## Which tab to put the code in

Use "Begin Routine" tab to pull out the current cat as `this_cat`

![](demos/variables/Screenshot 2024-07-18 152534.png)

## Which tab to put the code in

Use "End Routine" to increment the index ready to pull out the next cat.

![](demos/variables/Screenshot 2024-07-18 152546.png)

## Use `this_cat` as the Image

![](demos/variables/Screenshot 2024-07-18 153728.png)

Note that we have to change from "constant" to "set every repeat"

## Advanced note

We can also bypass the Image component altogether.

```{python}
#| eval: false

from psychopy import visual
my_image = visual.ImageStim(win=myWin)
my_image.Image = cats[i]
```


## Why declare fields in code?

* It doesn't always repay the effort to declare variables in code.
* In the last example the best way to present the cats in a sequence is the spreadsheet method.

:::{.callout-important title="to do"}
Justify declaring in code?
:::

# Randomising and pseudo-randomising sequences

n.b. a truly randomised sequence can be in the same order as the original sequence. Most often we want pseudo-randomised sequences that impose some constraints on true randomisation.

---

Let's say we want to randomise the order in which cats are presented across participants to avoid systematic order effects.

## Pure randomising

If we are using the spreadsheet method, randomisation is a property of the loop: 

* we can tell the loop to randomise the sequence of cats, 
* but we can't tell the loop to __pseudo__-randomise the sequence of cats.

## Pure randomising

![](demos/variables/Screenshot 2024-07-18 160058.png)

## Pure randomising

If we are using code we can use `shuffle` on the list to get randomisation (not yet pseudo-randomisation but see later for that)

```{python}
# We have to import the shuffle routine from the random library
from random import shuffle

# Make a list called `cats` containing the filenames.
cats = ['cat1.jpg', 'cat2.jpg', 'cat3.jpg']

# Shuffle the list
shuffle(cats)

# View the list
print(cats)
```

## Pseudo-randomising 

One advantage of shuffling in code is that we can impose pseudo-randomisation which is almost impossible using the spreadsheet method.

For example, let's say we never want the original order to be the outcome of shuffling the list.

## Pseudo-randomising {.scrollable}

* Make a list of cat images as before 

```{python}
original_cats = ['cat1.jpg', 'cat2.jpg', 'cat3.jpg']
```

* Make a faithful copy of the original list. At this point `current_cats` is the same as the `original_cats` list.
 
```{python}
current_cats = original_cats.copy()
```

## Pseudo-randomising {.scrollable}

* Next we say: 
  * __while the `current_cats` list is still the same as the original, shuffle the `current_cats` list__

```{python}
while current_cats == original_cats:
  shuffle(current_cats)
```

* Then verify that the resulting list is different from the original list

```{python}
print(current_cats)
```

## Putting it all together

code block for shuffling

```{python}
from random import shuffle
original_cats = ['cat1.jpg', 'cat2.jpg', 'cat3.jpg']
current_cats = original_cats.copy()
while current_cats == original_cats:
  shuffle(current_cats)
```

print to verify that the shuffled list is not the same as the original list

```{python}
print(current_cats)
```


# Many stimuli (pure code no Builder)

---

This runs in python without opening PsychoPy ...

![](demos/vis-search-no-builder/main.png)

---

... but you can also open it in PsychoPy and run it from  there

![](demos/vis-search-no-builder/main-in-coder.png)


# Logic / Flow Control

---

* Logic boils down to saying 'if ... then'

---

:::{.callout-important title="response needed"}
people asked for changing the flow based on a participant's earlier responses
:::

---

:::{.callout-important title="response needed"}
demonstrate `response.keys`
:::

---

:::{.callout-important title="response needed"}
demonstrate free-tect responses -- the enter your age example
:::


# Hardware and the `iohub` framework

## EEG

* EEG is handled by the parallel port component 
* In EEG all we are doing is sending messages into the data: recording of data from the electrodes is handled by an entirely separate system (separate recorder PC)
* The amplifiers send data from the electrodes over fibre-optic cables to a box that translates optical to usb and feeds the recorder PC usb signals representing activity at each electrode.

## EEG

* We send messages from the display PC to the recorder PC by feeding an additional channel into the box that translates optical to USB.
* So an EEG signal from the display PC acts like a dummy electrode channel

## EEG - the parallel port

* the parallel port is a really old channel of communication
* it was better than the previous alternative (serial port) because it allowed messages to be sent without waiting in a queue
* you can set it to send integers from 0 to 256
* 0 is 'off', everything else is a variant of 'on'

## EEG - parallel port messages

* a common mistake is to think that changing from '1' to '2' is a legitimate message whose content is '2' because sending '2' is a change of state from '1'.
* changing from '1' to '2' will be interpreted as _change to 'on' from 'on'_ which is no change at all -- the port will still be sending '1'
* if the last message was '1' and you now want to send '2', you have to go via '0'


## EEG - parallel port messages

* you have always been able to send parallel port messages in code.
* but now you can send messages in a parallel port Component

---

:::{.column-screen}
![](demos/eeg/Screenshot from 2024-07-21 19-13-57.png){width="75%"}
:::

By default, `"Stop data"` is set to 0 to ensure that any subsequent 'on' messages between 1 and 256 will be interpreted as a change of state from 'off' to 'on'

---

:::{.column-screen}
![](demos/eeg/Screenshot from 2024-07-21 19-20-17.png){width="75%"}
:::


You can send a signal at some time in seconds.milliseconds; after some number of frames; or **based upon some condition being satisfied**.

## EEG - conditional trigger

Since we can send a message as soon as some condition is satisfied, we can send a message as soon as the stimulus is visible on screen (for example).

Assume the Image component for the stimulus is named 'stimulus_1'. The 'Condition' would then be as follows (n.b. that we have to put a dollar sign in front of the actual python code so that the Builder knows we are supplying something to be evaluated rather than a literal piece of text)

```{python}
#| eval: false
$stimulus_1.status == STARTED
```

## EEG - conditional trigger

:::{.column-screen}
![](demos/eeg/Screenshot from 2024-07-21 19-36-30.png){width="100%"}
:::

## EEG - conditional trigger

Note that I shortened the duration from the default 1 second to 0.1 seconds. This is because you want to send the 0 (`"Stop data"` value) soon after the 'on' signal' so that the port is clean quickly in case you want to send another message quickly (maybe send a '2' as soon as the stimulus is no longer visible). If that '2' signal came while the port was still saying '1' then the '2' just would not be recognised as a change of state leading to no '2' message being sent (because '1' to '2' is 'on' to 'still on')

## TMS 

* TMS pulses are handled by the parallel port component.
* TMS pulses need to be sent in quick succession
* Components can do things fairly frequently -- but not more frequently than the frame rate.
* At 60 Hz this is once every 16.6 ms.
* Individual TMS pulses sometimes need to happen more quickly -- at 100 Hz is common, so every 10 ms 
* Faster than frame-rate actions can be done in loops in code components

## TMS - Alex

:::{.callout-important title="response needed"}
refer to Alex's TMS experiment
:::

## Wacom

* The Wacom tablet allows participants to trace paths through mazes so it can be used for way-finding and related tasks.
* There is no Wacom component but there is an `iohub` _device_ for Wacom in python

## Wacom - Marina

:::{.callout-important title="response needed"}
refer to Marina's Wacom experiment
:::

## Eye-tracking

* There is now an eye-tracking component but I haven't used it yet.
* There is an `iohub` _device_ for each eye-tracker in common use
* You can use mouse simulation of eye-movements while developing the experiment
    * this is because there is an iohub device for mouse and you can switch easily between different iohub devices (could run the same task with the Wacom pen device)

## Eye-tracking - Jan's experiment

:::{.callout-important title="response needed"}
refer to the foraging game
:::

# Add data from code to the csv file

## Add data from code to the csv file

* Everything supplied in a loop spreadsheet to a loop gets recorded in the output file.
* Everything computed by (non-Code) Components gets recorded to the output file
  * This covers response keys for keyboard components and the RTs for those responses for example

**BUT nothing that you create in Code gets recorded to the output file** unless you issue an instruction to record it.

## Add data from code to the csv file

The instruction is simple enough though:

```{python}
#| eval: false
thisExpAddData("accuracy threshold for block 1", acc_thresh_block_1)
```

The first argument is going to end up as the column header in the csv file.

The second argument is the value you want recorded in the relevant row in that column


## Add data from code to the csv file

PsychoPy output files are not very human-friendly.

For headers like `key_resp.resp` it can be hard to remember which of several keyboard response this column refers to when you are trying to identify the main response in the experiment at data analysis time

## Add data from code to the csv file

It is good practice to rename Components to get better output. If the keyboard component is the response to "Have you seen this face before?", a name like `face_familiarity.resp` might be better than `key_resp.resp`. 

Rename the Keyboard Component to `face_familiarity` to get variables:

* `face_familiarity.resp` for which key they pressed, 
* `face_familiarity.rt` for the RT, and 
* `face_familiarity.corr` for the accuracy.

## Add data from code to the csv file

You can exert finer control if you rename the variables using Code.

```{python}
#| eval: false
thisExpAddData("block 1 trial 1 keys pressed", key_resp.keys)
thisExpAddData("block 1 trial 1 accuracy", key_resp.corr)
thisExpAddData("block 1 trial 1 response time", key_resp.keys)
```

# Do not make multiple experiments for different conditions of the same experiment

---

Just feed in different spreadsheets using logic to choose the appropriate sheet for this run

:::{.callout-important title="response needed"}
More needed
:::

# How to use the GUI to offer options

---

* drop-downs
* enter demographics
* RECORD THOSE VALUES USING CODE

:::{.callout-important title="response needed"}
Does the GUI automatically record this?
:::


# How to compute an accuracy rate for a block and use it for thresholding

---

* Start with an empty list
* Per-trial add to the list 0 or 1 based on key_resp.corr or some explicit calculation of accuracy
* At end of block calculate the mean of the list for an accuracy rate
* say, `if rate better than 80% then end the practice block and continue to the experimental block`
```{python}
#| eval: false
if rate>.8:
  trials.finished = True
```

:::{.callout-important title="response needed"}
More needed
:::



# Complete experiments

# Documentation, Demos, Forums





# Online

# Python -> Javascript generation

## Sync with pavlovia

## Sync with pavlovia

clone, push, and pull.

## Surveys

## Replace Qualtrics with Surveys

* import qsf
* implement logic and conditional display of  a question

## Replace Qualtrics with Surveys - Daisy chaining

## Sona advert link

for the experimenter to administrate the SONA advert and slots

[https://psychologyresearchbu.sona-systems.com/exp_info.aspx?experiment_id=3698](https://psychologyresearchbu.sona-systems.com/exp_info.aspx?experiment_id=3698)

## SONA -> Survey link 

[https://run.pavlovia.org/pavlovia/survey-2024.1.0/?surveyId=97257dd7-a640-464a-8a54-1b237f5e46d4&participant=%SURVEY_CODE%](https://run.pavlovia.org/pavlovia/survey-2024.1.0/?surveyId=97257dd7-a640-464a-8a54-1b237f5e46d4&participant=%SURVEY_CODE%)

* [surveyId](surveyId) comes from pavlovia and identifies the survey you are going to

* [%SURVEY_CODE%](%SURVEY_CODE%) (confusingly) comes from SONA (not pavlovia) and identifies the SONA participant with a unique number like 12345. This number gets passed around all systems in the daisy chain, so that you can later join together all the responses that this participant made across all systems in the chain.

## Survey -> SONA link 

* base URL: 
  * [https://psychologyresearchbu.sona-systems.com/webstudy_credit.aspx](https://psychologyresearchbu.sona-systems.com/webstudy_credit.aspx)
* experiment_id: 
  * [?experiment_id=3698](?experiment_id=3698)
* credit token: 
  * [&credit_token=6a7fa06f44884643b23b8b9a273e27ba](&credit_token=6a7fa06f44884643b23b8b9a273e27ba)
* participant_id: 
  * [&survey_code={participant}](&survey_code={participant})

<!-- [https://psychologyresearchbu.sona-systems.com/webstudy_credit.aspx?experiment_id=3698&credit_token=6a7fa06f44884643b23b8b9a273e27ba&survey_code={participant}](https://psychologyresearchbu.sona-systems.com/webstudy_credit.aspx?experiment_id=3698&credit_token=6a7fa06f44884643b23b8b9a273e27ba&survey_code={participant}) -->

## Survey -> SONA link 
* You get this from SONA - it is the return URL
* It encodes the "experiment" identifier - actually an id for the advert
* It encodes a credit token so that an individual participant can be marked as 'participated' to avoid a single individual racking up multiple credits
* It encodes the participant number itself -- the one that was sent out as %SURVEY_CODE%


# Shelf

This is a new feature that permits **counterbalancing in online experiments**

There is no equivalent to "write to csv" in online experiments, so now there is an online place where you can store variable: value pairs like how many participants have participated in each level of counterbalancing so far